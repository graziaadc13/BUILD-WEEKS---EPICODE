{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fb0650d-7abf-4521-b319-7e5c2ae9138f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: selenium in c:\\users\\grits\\appdata\\roaming\\python\\python312\\site-packages (4.28.1)\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\grits\\appdata\\roaming\\python\\python312\\site-packages (4.0.2)\n",
      "Requirement already satisfied: pandas in d:\\programdata\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in d:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\grits\\appdata\\roaming\\python\\python312\\site-packages (from selenium) (0.28.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\grits\\appdata\\roaming\\python\\python312\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in d:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (2025.4.26)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in d:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (4.11.0)\n",
      "Requirement already satisfied: websocket-client~=1.8 in d:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: requests in d:\\programdata\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in d:\\programdata\\anaconda3\\lib\\site-packages (from webdriver-manager) (0.21.0)\n",
      "Requirement already satisfied: packaging in d:\\programdata\\anaconda3\\lib\\site-packages (from webdriver-manager) (24.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\grits\\appdata\\roaming\\python\\python312\\site-packages (from trio~=0.17->selenium) (25.1.0)\n",
      "Requirement already satisfied: sortedcontainers in d:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in d:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.7)\n",
      "Requirement already satisfied: outcome in c:\\users\\grits\\appdata\\roaming\\python\\python312\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in d:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\grits\\appdata\\roaming\\python\\python312\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in d:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.3.2)\n",
      "Requirement already satisfied: pycparser in d:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in d:\\programdata\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium webdriver-manager pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e421e92f-c8e8-4dae-b5eb-be68dc3c6b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "📄 Inserisci il colore delle scarpe (es. nero, rosso, blu):  beige\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Avvio scraping per colore “beige” con URL:\n",
      "https://www.amazon.it/s?k=scarpe&i=fashion&rh=n%3A5512286031%2Cp_123%3A193963%257C389207%257C597269%257C9437%2Cp_n_feature_thirty-three_browse-bin%3A96332046031%2Cp_n_size_two_browse-vebin%3A14223342031&dc&__mk_it_IT=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=1BZC206652037&qid=1747854471&rnid=14223337031&sprefix=scarpe%2Cfashion%2C353&ref=sr_nr_p_n_size_two_browse-vebin_9&ds=v1%3A2WqYxGi%2FZ4%2BrCWdr3wLYgiFe4dsE%2FtfnL3DLmq578WQ\n",
      "\n",
      "🔍 Scraping pagina 1…\n",
      "🔍 Scraping pagina 2…\n",
      "🔍 Scraping pagina 3…\n",
      "🔍 Scraping pagina 4…\n",
      "🔍 Scraping pagina 5…\n",
      "🔍 Scraping pagina 6…\n",
      "🔍 Scraping pagina 7…\n",
      "🔍 Scraping pagina 8…\n",
      "🔍 Scraping pagina 9…\n",
      "🔍 Scraping pagina 10…\n",
      "🔍 Scraping pagina 11…\n",
      "🔍 Scraping pagina 12…\n",
      "🔍 Scraping pagina 13…\n",
      "🔍 Scraping pagina 14…\n",
      "🔍 Scraping pagina 15…\n",
      "🔍 Scraping pagina 16…\n",
      "🔍 Scraping pagina 17…\n",
      "🔍 Scraping pagina 18…\n",
      "🔍 Scraping pagina 19…\n",
      "🔍 Scraping pagina 20…\n",
      "🔍 Scraping pagina 21…\n",
      "✅ Fine paginazione.\n",
      "[OK] CSV creato con 1169 righe: amazon_4marche_beige.csv\n",
      "      Marchio                                     Nome            Prezzo  \\\n",
      "0  Lumberjack       Agatha, Scarpe da Ginnastica Donna           37,79 €   \n",
      "1        Geox    D Desya A, Scarpe da Ginnastica Donna           60,66 €   \n",
      "2        Geox                 D Ilde A, Sneakers Donna  Mediano: 63,85 €   \n",
      "3        Geox                D Sukie B, Sneakers Donna           63,85 €   \n",
      "4        Geox  D Blomiee E, Scarpe da Ginnastica Donna           80,29 €   \n",
      "\n",
      "       Valutazione  \n",
      "0  4,2 su 5 stelle  \n",
      "1  4,6 su 5 stelle  \n",
      "2  4,3 su 5 stelle  \n",
      "3  4,6 su 5 stelle  \n",
      "4  3,9 su 5 stelle  \n"
     ]
    }
   ],
   "source": [
    "#TUTTE SCARPE (4 MARCHI)\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# INPUT del colore \n",
    "colore = input(\"📄 Inserisci il colore delle scarpe (es. nero, rosso, blu): \").strip().lower()\n",
    "# Associa ogni colore all'URL di ricerca corrispondente\n",
    "color_urls = {\n",
    "    \"nero\":  \"https://www.amazon.it/s?k=scarpe&i=fashion&rh=n%3A5512286031%2Cp_123%3A193963%257C389207%257C597269%257C9437%2Cp_n_feature_thirty-three_browse-bin%3A96332046031%2Cp_n_size_two_browse-vebin%3A14223338031&dc&__mk_it_IT=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=1BZC206652037&qid=1747852639&rnid=14223337031&sprefix=scarpe%2Cfashion%2C353&ref=sr_nr_p_n_size_two_browse-vebin_14&ds=v1%3A1PzeTi1BLCu5KVubYGrFumIAM%2BpKk%2F8gks7h2Ia8WN4\",\n",
    "    \"rosso\": \"https://www.amazon.it/s?k=scarpe&i=fashion&rh=n%3A5512286031%2Cp_123%3A193963%257C389207%257C597269%257C9437%2Cp_n_feature_thirty-three_browse-bin%3A96332046031%2Cp_n_size_two_browse-vebin%3A14223343031&dc&__mk_it_IT=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=1BZC206652037&qid=1747854369&rnid=14223337031&sprefix=scarpe%2Cfashion%2C353&ref=sr_nr_p_n_size_two_browse-vebin_11&ds=v1%3AqOsRINYmz5WAeK%2Fyoe9E2J%2B6pEHOWGPj2yjP5n9ZHYY\",\n",
    "    \"marrone\":   \"https://www.amazon.it/s?k=scarpe&i=fashion&rh=n%3A5512286031%2Cp_123%3A193963%257C389207%257C597269%257C9437%2Cp_n_feature_thirty-three_browse-bin%3A96332046031%2Cp_n_size_two_browse-vebin%3A14223341031&dc&__mk_it_IT=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=1BZC206652037&qid=1747854411&rnid=14223337031&sprefix=scarpe%2Cfashion%2C353&ref=sr_nr_p_n_size_two_browse-vebin_14&ds=v1%3ApS3xEGdxgIxIZi9I4zW7O%2BuKRhD30cm21vF%2BU7%2Fq7A8\",\n",
    "    \"beige\": \"https://www.amazon.it/s?k=scarpe&i=fashion&rh=n%3A5512286031%2Cp_123%3A193963%257C389207%257C597269%257C9437%2Cp_n_feature_thirty-three_browse-bin%3A96332046031%2Cp_n_size_two_browse-vebin%3A14223342031&dc&__mk_it_IT=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=1BZC206652037&qid=1747854471&rnid=14223337031&sprefix=scarpe%2Cfashion%2C353&ref=sr_nr_p_n_size_two_browse-vebin_9&ds=v1%3A2WqYxGi%2FZ4%2BrCWdr3wLYgiFe4dsE%2FtfnL3DLmq578WQ\"\n",
    "    # aggiungi qui gli altri colori e i loro URL\n",
    "}\n",
    "if colore not in color_urls:\n",
    "    print(f\"⚠️ Colore non riconosciuto. Scegli tra: {', '.join(color_urls.keys())}\")\n",
    "    exit(1)\n",
    "\n",
    "start_url = color_urls[colore]\n",
    "print(f\"🔍 Avvio scraping per colore “{colore}” con URL:\\n{start_url}\\n\")\n",
    "\n",
    "\n",
    "#1) Setup Selenium con opzioni anti‐bot \n",
    "options = Options()\n",
    "# commenta headless per minimizzare il fingerprinting\n",
    "# options.headless = True\n",
    "options.add_argument(\"--window-size=1920,1080\")\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option(\"useAutomationExtension\", False)\n",
    "options.add_argument(\n",
    "    \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "    \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "    \"Chrome/118.0.0.0 Safari/537.36\"\n",
    ")\n",
    "\n",
    "driver = webdriver.Chrome(\n",
    "    service=Service(ChromeDriverManager().install()),\n",
    "    options=options\n",
    ")\n",
    "\n",
    "\n",
    "# 2) URL di partenza \n",
    "#start_url = (\n",
    "    \n",
    "    #\"https://www.amazon.it/s?k=scarpe+stivaletti+donna&i=fashion&rh=n%3A5512286031%2Cp_123%3A193963%257C237326%257C389207%257C9437&dc=&__mk_it_IT=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=1KW1VKWJQPEUX&qid=1747845895&rnid=2492969031&sprefix=scarpe+stivaletti+do%2Cfashion%2C189&xpid=H08luOnxQvkrq&ref=sr_nr_p_36_0_0&low-price=290&high-price=\"\n",
    "#)\n",
    "driver.get(start_url)\n",
    "time.sleep(7)\n",
    "\n",
    "# 3) Loop di paginazione e scraping \n",
    "page = 1\n",
    "all_brands = []\n",
    "all_names = []\n",
    "all_prices = []\n",
    "all_ratings = []\n",
    "\n",
    "while True:\n",
    "    print(f\"Scraping pagina {page}…\")\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    # Estrae i dati\n",
    "    brand_elems   = soup.find_all('span', class_=\"a-size-base-plus a-color-base\")\n",
    "    name_elems    = soup.find_all(\"h2\", class_=\"a-size-base-plus a-spacing-none a-color-base a-text-normal\")\n",
    "    price_elems   = soup.find_all(\"span\", class_=\"a-offscreen\")\n",
    "    rating_elems  = soup.select(\"span.a-icon-alt\")\n",
    "   \n",
    "\n",
    "    # Pulisce  i testi\n",
    "    brands  = [b.text.strip() for b in brand_elems]\n",
    "    names   = [n.text.strip() for n in name_elems]\n",
    "    prices  = [p.text.strip() for p in price_elems]\n",
    "    ratings = [r.text.strip() for r in rating_elems]\n",
    "\n",
    "    #Pad per i nulli\n",
    "    max_len = max(len(brands), len(names), len(prices), len(ratings))\n",
    "\n",
    "    def pad_list(lst):\n",
    "        return lst + [np.nan] * (max_len - len(lst))\n",
    "\n",
    "    brands = pad_list(brands)\n",
    "    names = pad_list(names)\n",
    "    prices = pad_list(prices)\n",
    "    ratings = pad_list(ratings)\n",
    "    \n",
    "        # Accumula\n",
    "    all_brands  .extend(brands)\n",
    "    all_names   .extend(names)\n",
    "    all_prices  .extend(prices)\n",
    "    all_ratings .extend(ratings)\n",
    "\n",
    "    # Prova a cliccare il link della pagina successiva\n",
    "    try:\n",
    "        selector = f\"a.s-pagination-item[aria-label='Vai alla pagina {page+1}']\"\n",
    "        next_btn = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "\n",
    "        # Porta il bottone al centro della viewport\n",
    "        driver.execute_script(\n",
    "            \"arguments[0].scrollIntoView({block: 'center', inline: 'center'});\",\n",
    "            next_btn\n",
    "        )\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        # Click via JS per evitare intercettazioni\n",
    "        driver.execute_script(\"arguments[0].click();\", next_btn)\n",
    "\n",
    "        page += 1\n",
    "        time.sleep(7)  # attendi il caricamento della nuova pagina\n",
    "    except NoSuchElementException:\n",
    "        print(\"✅ Fine paginazione.\")\n",
    "        break\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "# 4) Creazione DataFrame ed export CSV---\n",
    "df = pd.DataFrame({\n",
    "    \"Marchio\":     all_brands,\n",
    "    \"Nome\":        all_names,\n",
    "    \"Prezzo\":      all_prices,\n",
    "    \"Valutazione\": all_ratings\n",
    "})\n",
    "\n",
    "output_file = f\"amazon_4marche_{colore}.csv\"\n",
    "df.to_csv(output_file, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"[OK] CSV creato con {len(df)} righe: {output_file}\")\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48952b12-a87b-4ae1-9cf3-7140a71fa881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
